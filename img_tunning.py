from datasets import load_dataset, DatasetDict
from transformers import AutoImageProcessor, AutoModelForImageClassification
from transformers import TrainingArguments, Trainer
import evaluate
import numpy as np

# 2Ô∏è‚É£ Cargar CIFAR-10
dataset = load_dataset("cifar10")

# 3Ô∏è‚É£ Seleccionar subset peque√±o para pruebas CPU
train_dataset = dataset['train'].shuffle(seed=21).select(range(500))
test_dataset = dataset['test'].shuffle(seed=21).select(range(100))

# 4Ô∏è‚É£ Separar validaci√≥n
split = train_dataset.train_test_split(test_size=0.1, seed=42)
dataset_final = DatasetDict({
    'train': split['train'],
    'validation': split['test'],
    'test': test_dataset
})

# 5Ô∏è‚É£ Configurar AutoImageProcessor
model_name = "google/vit-base-patch16-224"
processor = AutoImageProcessor.from_pretrained(model_name)

# 6Ô∏è‚É£ Preprocesamiento correcto (sin PIL ni torch transforms)
def preprocess(example):
    processed = processor(images=example["img"], return_tensors=None)
    example["pixel_values"] = processed["pixel_values"][0]  # shape (3,224,224)
    return example

dataset_final = dataset_final.map(preprocess, batched=False)

# 7Ô∏è‚É£ Remover columna 'img' que ya no necesitamos
dataset_final = dataset_final.remove_columns(['img'])

# 8Ô∏è‚É£ Cargar modelo ViT
num_labels = 10
model = AutoModelForImageClassification.from_pretrained(
    model_name,
    num_labels=num_labels,
    ignore_mismatched_sizes=True
)

# 9Ô∏è‚É£ M√©trica
metric = evaluate.load("accuracy")
def compute_metrics(p):
    preds = p.predictions.argmax(-1)
    return metric.compute(predictions=preds, references=p.label_ids)

# üîü TrainingArguments (CPU-friendly)
training_args = TrainingArguments(
    output_dir="./vit-cifar10",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=2,  # muy peque√±o para CPU
    per_device_eval_batch_size=2,
    learning_rate=2e-5,
    num_train_epochs=1,  # prueba r√°pida
    logging_dir="./logs",
    load_best_model_at_end=True,
)

# 1Ô∏è‚É£1Ô∏è‚É£ Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=dataset_final['train'],
    eval_dataset=dataset_final['validation'],
    compute_metrics=compute_metrics,
)

# 1Ô∏è‚É£2Ô∏è‚É£ Entrenar
trainer.train()

# 1Ô∏è‚É£3Ô∏è‚É£ Evaluar test final
test_results = trainer.evaluate(dataset_final['test'])
print("Test Accuracy:", test_results['eval_accuracy'])

# 1Ô∏è‚É£4Ô∏è‚É£ Guardar modelo
model.save_pretrained("./mi_modelo_vit_cifar10")
processor.save_pretrained("./mi_modelo_vit_cifar10")